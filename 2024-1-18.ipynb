{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def fetch(session, url):\n",
    "    async with session.get(url) as response:\n",
    "        return await response.text(), response.status\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        html, status = await fetch(session, 'https://cuiqingcai.com')\n",
    "        print(f'html: {html[:100]}...')\n",
    "        print(f'status: {status}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html: <!DOCTYPE html>\n",
      "<html lang=\"zh-CN\">\n",
      "\n",
      "<head>\n",
      "  <meta charset=\"UTF-8\">\n",
      "  <meta name=\"viewport\" content...\n",
      "status: 200\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "async def fetch(session, url):\n",
    "    async with session.get(url) as response:\n",
    "        return await response.text(), response.status\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "            html, status = await fetch(session, 'https://cuiqingcai.com')\n",
    "            print(f'html: {html[:100]}...')\n",
    "            print(f'status: {status}')\n",
    "if __name__ == '__main__':\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "async def main():\n",
    "    timeout = aiohttp.ClientTimeout(total=1)\n",
    "    async with aiohttp.ClientSession(timeout=timeout) as session:\n",
    "        async with session.get('https://httpbin.org/get') as response:\n",
    "            print('status:', response.status)\n",
    "if __name__ == '__main__':\n",
    "    asyncio.get_event_loop().run_until_complete(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "async def main():\n",
    "    data = {'name': 'germey', 'age': 25}\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post('http://httpbin.org/post', data=data) as resp:\n",
    "            print(await resp.text())\n",
    "\n",
    "if __name__ == '_main_':\n",
    "    asyncio.get_event_loop().run_until_complete(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,format='%(asctime)s - %(levelname)s: %(message)s')\n",
    "INDEX_URL = 'https://spa16.scrape.center/{offset}'\n",
    "DETAIL_URL = 'https://spa16.scrape.center/{id}'\n",
    "\n",
    "PAGE_SIZE = 18\n",
    "PAGE_NUMBER = 100\n",
    "CONCURRENCY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "semaphore = asyncio.Semaphore(CONCURRENCY)\n",
    "session = None\n",
    "async def scrape_api(url):\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            logging.info('scraping %s', url)\n",
    "            async with session.get(url) as response:\n",
    "                return await response.json()\n",
    "        except aiohttp.ClientError:\n",
    "            logging.error('error occurred while scraping %s', url, exc_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_index(page):\n",
    "    url = INDEX_URL.format(offset=PAGE_SIZE * (page - 1))\n",
    "    return await scrape_api(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 17:24:09,478 - INFO: scraping https://spa16.scrape.center/0\n",
      "2024-01-19 17:24:09,480 - INFO: scraping https://spa16.scrape.center/18\n",
      "2024-01-19 17:24:09,481 - INFO: scraping https://spa16.scrape.center/36\n",
      "2024-01-19 17:24:09,483 - INFO: scraping https://spa16.scrape.center/54\n",
      "2024-01-19 17:24:09,484 - INFO: scraping https://spa16.scrape.center/72\n",
      "2024-01-19 17:24:10,343 - ERROR: error occurred while scraping https://spa16.scrape.center/0\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:10,361 - INFO: scraping https://spa16.scrape.center/90\n",
      "2024-01-19 17:24:10,363 - ERROR: error occurred while scraping https://spa16.scrape.center/72\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:10,365 - ERROR: error occurred while scraping https://spa16.scrape.center/36\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:10,367 - ERROR: error occurred while scraping https://spa16.scrape.center/18\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:10,370 - INFO: scraping https://spa16.scrape.center/108\n",
      "2024-01-19 17:24:10,371 - INFO: scraping https://spa16.scrape.center/126\n",
      "2024-01-19 17:24:10,372 - INFO: scraping https://spa16.scrape.center/144\n",
      "2024-01-19 17:24:10,482 - ERROR: error occurred while scraping https://spa16.scrape.center/90\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:10,484 - INFO: scraping https://spa16.scrape.center/162\n",
      "2024-01-19 17:24:10,509 - ERROR: error occurred while scraping https://spa16.scrape.center/126\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:10,511 - INFO: scraping https://spa16.scrape.center/180\n",
      "2024-01-19 17:24:10,521 - ERROR: error occurred while scraping https://spa16.scrape.center/108\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:10,523 - INFO: scraping https://spa16.scrape.center/198\n",
      "2024-01-19 17:24:10,525 - ERROR: error occurred while scraping https://spa16.scrape.center/144\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:10,528 - INFO: scraping https://spa16.scrape.center/216\n",
      "2024-01-19 17:24:10,655 - ERROR: error occurred while scraping https://spa16.scrape.center/198\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:10,657 - INFO: scraping https://spa16.scrape.center/234\n",
      "2024-01-19 17:24:10,666 - ERROR: error occurred while scraping https://spa16.scrape.center/216\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:10,668 - INFO: scraping https://spa16.scrape.center/252\n",
      "2024-01-19 17:24:10,671 - ERROR: error occurred while scraping https://spa16.scrape.center/162\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:10,672 - INFO: scraping https://spa16.scrape.center/270\n",
      "2024-01-19 17:24:10,792 - ERROR: error occurred while scraping https://spa16.scrape.center/234\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:10,794 - INFO: scraping https://spa16.scrape.center/288\n",
      "2024-01-19 17:24:10,802 - ERROR: error occurred while scraping https://spa16.scrape.center/252\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:10,804 - INFO: scraping https://spa16.scrape.center/306\n",
      "2024-01-19 17:24:10,808 - ERROR: error occurred while scraping https://spa16.scrape.center/270\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:10,810 - INFO: scraping https://spa16.scrape.center/324\n",
      "2024-01-19 17:24:10,919 - ERROR: error occurred while scraping https://spa16.scrape.center/288\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:10,919 - INFO: scraping https://spa16.scrape.center/342\n",
      "2024-01-19 17:24:11,172 - ERROR: error occurred while scraping https://spa16.scrape.center/324\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:11,174 - INFO: scraping https://spa16.scrape.center/360\n",
      "2024-01-19 17:24:11,191 - ERROR: error occurred while scraping https://spa16.scrape.center/306\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:11,193 - INFO: scraping https://spa16.scrape.center/378\n",
      "2024-01-19 17:24:11,563 - ERROR: error occurred while scraping https://spa16.scrape.center/360\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:11,564 - INFO: scraping https://spa16.scrape.center/396\n",
      "2024-01-19 17:24:11,652 - ERROR: error occurred while scraping https://spa16.scrape.center/180\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:11,653 - INFO: scraping https://spa16.scrape.center/414\n",
      "2024-01-19 17:24:11,693 - ERROR: error occurred while scraping https://spa16.scrape.center/396\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:11,695 - INFO: scraping https://spa16.scrape.center/432\n",
      "2024-01-19 17:24:11,794 - ERROR: error occurred while scraping https://spa16.scrape.center/414\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:11,795 - INFO: scraping https://spa16.scrape.center/450\n",
      "2024-01-19 17:24:11,818 - ERROR: error occurred while scraping https://spa16.scrape.center/432\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:11,820 - INFO: scraping https://spa16.scrape.center/468\n",
      "2024-01-19 17:24:11,922 - ERROR: error occurred while scraping https://spa16.scrape.center/450\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:11,923 - INFO: scraping https://spa16.scrape.center/486\n",
      "2024-01-19 17:24:11,945 - ERROR: error occurred while scraping https://spa16.scrape.center/468\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:11,946 - INFO: scraping https://spa16.scrape.center/504\n",
      "2024-01-19 17:24:12,046 - ERROR: error occurred while scraping https://spa16.scrape.center/486\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,048 - INFO: scraping https://spa16.scrape.center/522\n",
      "2024-01-19 17:24:12,054 - ERROR: error occurred while scraping https://spa16.scrape.center/342\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,055 - INFO: scraping https://spa16.scrape.center/540\n",
      "2024-01-19 17:24:12,068 - ERROR: error occurred while scraping https://spa16.scrape.center/504\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,070 - INFO: scraping https://spa16.scrape.center/558\n",
      "2024-01-19 17:24:12,179 - ERROR: error occurred while scraping https://spa16.scrape.center/540\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,181 - INFO: scraping https://spa16.scrape.center/576\n",
      "2024-01-19 17:24:12,183 - ERROR: error occurred while scraping https://spa16.scrape.center/522\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,185 - INFO: scraping https://spa16.scrape.center/594\n",
      "2024-01-19 17:24:12,302 - ERROR: error occurred while scraping https://spa16.scrape.center/576\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,303 - INFO: scraping https://spa16.scrape.center/612\n",
      "2024-01-19 17:24:12,309 - ERROR: error occurred while scraping https://spa16.scrape.center/378\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,311 - INFO: scraping https://spa16.scrape.center/630\n",
      "2024-01-19 17:24:12,313 - ERROR: error occurred while scraping https://spa16.scrape.center/594\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,315 - INFO: scraping https://spa16.scrape.center/648\n",
      "2024-01-19 17:24:12,424 - ERROR: error occurred while scraping https://spa16.scrape.center/612\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,426 - INFO: scraping https://spa16.scrape.center/666\n",
      "2024-01-19 17:24:12,433 - ERROR: error occurred while scraping https://spa16.scrape.center/630\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,436 - INFO: scraping https://spa16.scrape.center/684\n",
      "2024-01-19 17:24:12,438 - ERROR: error occurred while scraping https://spa16.scrape.center/648\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,440 - INFO: scraping https://spa16.scrape.center/702\n",
      "2024-01-19 17:24:12,442 - ERROR: error occurred while scraping https://spa16.scrape.center/54\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,444 - INFO: scraping https://spa16.scrape.center/720\n",
      "2024-01-19 17:24:12,554 - ERROR: error occurred while scraping https://spa16.scrape.center/684\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,555 - INFO: scraping https://spa16.scrape.center/738\n",
      "2024-01-19 17:24:12,564 - ERROR: error occurred while scraping https://spa16.scrape.center/702\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,566 - INFO: scraping https://spa16.scrape.center/756\n",
      "2024-01-19 17:24:12,569 - ERROR: error occurred while scraping https://spa16.scrape.center/720\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,570 - INFO: scraping https://spa16.scrape.center/774\n",
      "2024-01-19 17:24:12,619 - ERROR: error occurred while scraping https://spa16.scrape.center/558\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,621 - INFO: scraping https://spa16.scrape.center/792\n",
      "2024-01-19 17:24:12,696 - ERROR: error occurred while scraping https://spa16.scrape.center/756\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,698 - INFO: scraping https://spa16.scrape.center/810\n",
      "2024-01-19 17:24:12,743 - ERROR: error occurred while scraping https://spa16.scrape.center/792\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,744 - INFO: scraping https://spa16.scrape.center/828\n",
      "2024-01-19 17:24:12,820 - ERROR: error occurred while scraping https://spa16.scrape.center/666\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,822 - INFO: scraping https://spa16.scrape.center/846\n",
      "2024-01-19 17:24:12,824 - ERROR: error occurred while scraping https://spa16.scrape.center/810\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,825 - INFO: scraping https://spa16.scrape.center/864\n",
      "2024-01-19 17:24:12,868 - ERROR: error occurred while scraping https://spa16.scrape.center/828\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,870 - INFO: scraping https://spa16.scrape.center/882\n",
      "2024-01-19 17:24:12,944 - ERROR: error occurred while scraping https://spa16.scrape.center/738\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,945 - INFO: scraping https://spa16.scrape.center/900\n",
      "2024-01-19 17:24:12,950 - ERROR: error occurred while scraping https://spa16.scrape.center/864\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,951 - INFO: scraping https://spa16.scrape.center/918\n",
      "2024-01-19 17:24:12,956 - ERROR: error occurred while scraping https://spa16.scrape.center/774\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:12,958 - INFO: scraping https://spa16.scrape.center/936\n",
      "2024-01-19 17:24:13,069 - ERROR: error occurred while scraping https://spa16.scrape.center/918\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,070 - INFO: scraping https://spa16.scrape.center/954\n",
      "2024-01-19 17:24:13,072 - ERROR: error occurred while scraping https://spa16.scrape.center/900\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,074 - INFO: scraping https://spa16.scrape.center/972\n",
      "2024-01-19 17:24:13,194 - ERROR: error occurred while scraping https://spa16.scrape.center/972\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,196 - INFO: scraping https://spa16.scrape.center/990\n",
      "2024-01-19 17:24:13,198 - ERROR: error occurred while scraping https://spa16.scrape.center/954\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,200 - INFO: scraping https://spa16.scrape.center/1008\n",
      "2024-01-19 17:24:13,221 - ERROR: error occurred while scraping https://spa16.scrape.center/846\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,223 - INFO: scraping https://spa16.scrape.center/1026\n",
      "2024-01-19 17:24:13,348 - ERROR: error occurred while scraping https://spa16.scrape.center/1026\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,350 - INFO: scraping https://spa16.scrape.center/1044\n",
      "2024-01-19 17:24:13,370 - ERROR: error occurred while scraping https://spa16.scrape.center/882\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,372 - INFO: scraping https://spa16.scrape.center/1062\n",
      "2024-01-19 17:24:13,481 - ERROR: error occurred while scraping https://spa16.scrape.center/1044\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,482 - INFO: scraping https://spa16.scrape.center/1080\n",
      "2024-01-19 17:24:13,497 - ERROR: error occurred while scraping https://spa16.scrape.center/1062\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,498 - INFO: scraping https://spa16.scrape.center/1098\n",
      "2024-01-19 17:24:13,501 - ERROR: error occurred while scraping https://spa16.scrape.center/1008\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,502 - INFO: scraping https://spa16.scrape.center/1116\n",
      "2024-01-19 17:24:13,588 - ERROR: error occurred while scraping https://spa16.scrape.center/990\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,590 - INFO: scraping https://spa16.scrape.center/1134\n",
      "2024-01-19 17:24:13,610 - ERROR: error occurred while scraping https://spa16.scrape.center/1080\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,612 - INFO: scraping https://spa16.scrape.center/1152\n",
      "2024-01-19 17:24:13,625 - ERROR: error occurred while scraping https://spa16.scrape.center/1116\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,627 - INFO: scraping https://spa16.scrape.center/1170\n",
      "2024-01-19 17:24:13,680 - ERROR: error occurred while scraping https://spa16.scrape.center/1098\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,682 - INFO: scraping https://spa16.scrape.center/1188\n",
      "2024-01-19 17:24:13,718 - ERROR: error occurred while scraping https://spa16.scrape.center/1134\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,720 - INFO: scraping https://spa16.scrape.center/1206\n",
      "2024-01-19 17:24:13,817 - ERROR: error occurred while scraping https://spa16.scrape.center/1188\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,819 - INFO: scraping https://spa16.scrape.center/1224\n",
      "2024-01-19 17:24:13,853 - ERROR: error occurred while scraping https://spa16.scrape.center/1206\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,854 - INFO: scraping https://spa16.scrape.center/1242\n",
      "2024-01-19 17:24:13,946 - ERROR: error occurred while scraping https://spa16.scrape.center/1224\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:13,947 - INFO: scraping https://spa16.scrape.center/1260\n",
      "2024-01-19 17:24:14,067 - ERROR: error occurred while scraping https://spa16.scrape.center/1260\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:14,068 - INFO: scraping https://spa16.scrape.center/1278\n",
      "2024-01-19 17:24:14,095 - ERROR: error occurred while scraping https://spa16.scrape.center/936\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:14,096 - INFO: scraping https://spa16.scrape.center/1296\n",
      "2024-01-19 17:24:14,148 - ERROR: error occurred while scraping https://spa16.scrape.center/1242\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:14,149 - INFO: scraping https://spa16.scrape.center/1314\n",
      "2024-01-19 17:24:14,195 - ERROR: error occurred while scraping https://spa16.scrape.center/1278\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:14,197 - INFO: scraping https://spa16.scrape.center/1332\n",
      "2024-01-19 17:24:14,221 - ERROR: error occurred while scraping https://spa16.scrape.center/1296\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:14,222 - INFO: scraping https://spa16.scrape.center/1350\n",
      "2024-01-19 17:24:14,293 - ERROR: error occurred while scraping https://spa16.scrape.center/1314\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:14,294 - INFO: scraping https://spa16.scrape.center/1368\n",
      "2024-01-19 17:24:14,339 - ERROR: error occurred while scraping https://spa16.scrape.center/1332\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:14,340 - INFO: scraping https://spa16.scrape.center/1386\n",
      "2024-01-19 17:24:14,357 - ERROR: error occurred while scraping https://spa16.scrape.center/1350\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:14,359 - INFO: scraping https://spa16.scrape.center/1404\n",
      "2024-01-19 17:24:14,462 - ERROR: error occurred while scraping https://spa16.scrape.center/1386\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:14,463 - INFO: scraping https://spa16.scrape.center/1422\n",
      "2024-01-19 17:24:14,490 - ERROR: error occurred while scraping https://spa16.scrape.center/1404\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:14,491 - INFO: scraping https://spa16.scrape.center/1440\n",
      "2024-01-19 17:24:14,613 - ERROR: error occurred while scraping https://spa16.scrape.center/1440\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:14,615 - INFO: scraping https://spa16.scrape.center/1458\n",
      "2024-01-19 17:24:14,755 - ERROR: error occurred while scraping https://spa16.scrape.center/1458\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:14,757 - INFO: scraping https://spa16.scrape.center/1476\n",
      "2024-01-19 17:24:15,018 - ERROR: error occurred while scraping https://spa16.scrape.center/1152\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:15,020 - INFO: scraping https://spa16.scrape.center/1494\n",
      "2024-01-19 17:24:15,431 - ERROR: error occurred while scraping https://spa16.scrape.center/1368\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:15,433 - INFO: scraping https://spa16.scrape.center/1512\n",
      "2024-01-19 17:24:15,557 - ERROR: error occurred while scraping https://spa16.scrape.center/1512\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:15,559 - INFO: scraping https://spa16.scrape.center/1530\n",
      "2024-01-19 17:24:15,725 - ERROR: error occurred while scraping https://spa16.scrape.center/1494\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:15,726 - INFO: scraping https://spa16.scrape.center/1548\n",
      "2024-01-19 17:24:16,639 - ERROR: error occurred while scraping https://spa16.scrape.center/1548\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:16,640 - INFO: scraping https://spa16.scrape.center/1566\n",
      "2024-01-19 17:24:16,759 - ERROR: error occurred while scraping https://spa16.scrape.center/1530\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:16,760 - INFO: scraping https://spa16.scrape.center/1584\n",
      "2024-01-19 17:24:16,783 - ERROR: error occurred while scraping https://spa16.scrape.center/1566\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:16,785 - INFO: scraping https://spa16.scrape.center/1602\n",
      "2024-01-19 17:24:16,888 - ERROR: error occurred while scraping https://spa16.scrape.center/1584\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:16,889 - INFO: scraping https://spa16.scrape.center/1620\n",
      "2024-01-19 17:24:16,907 - ERROR: error occurred while scraping https://spa16.scrape.center/1602\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:16,908 - INFO: scraping https://spa16.scrape.center/1638\n",
      "2024-01-19 17:24:17,280 - ERROR: error occurred while scraping https://spa16.scrape.center/1620\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:17,282 - INFO: scraping https://spa16.scrape.center/1656\n",
      "2024-01-19 17:24:17,413 - ERROR: error occurred while scraping https://spa16.scrape.center/1656\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:17,415 - INFO: scraping https://spa16.scrape.center/1674\n",
      "2024-01-19 17:24:17,434 - ERROR: error occurred while scraping https://spa16.scrape.center/1476\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:17,437 - INFO: scraping https://spa16.scrape.center/1692\n",
      "2024-01-19 17:24:17,543 - ERROR: error occurred while scraping https://spa16.scrape.center/1674\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:17,544 - INFO: scraping https://spa16.scrape.center/1710\n",
      "2024-01-19 17:24:17,563 - ERROR: error occurred while scraping https://spa16.scrape.center/1692\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:17,565 - INFO: scraping https://spa16.scrape.center/1728\n",
      "2024-01-19 17:24:17,671 - ERROR: error occurred while scraping https://spa16.scrape.center/1710\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:17,673 - INFO: scraping https://spa16.scrape.center/1746\n",
      "2024-01-19 17:24:17,688 - ERROR: error occurred while scraping https://spa16.scrape.center/1728\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:17,690 - INFO: scraping https://spa16.scrape.center/1764\n",
      "2024-01-19 17:24:17,804 - ERROR: error occurred while scraping https://spa16.scrape.center/1746\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:17,805 - INFO: scraping https://spa16.scrape.center/1782\n",
      "2024-01-19 17:24:17,813 - ERROR: error occurred while scraping https://spa16.scrape.center/1764\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:17,931 - ERROR: error occurred while scraping https://spa16.scrape.center/1782\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:18,039 - ERROR: error occurred while scraping https://spa16.scrape.center/1638\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "2024-01-19 17:24:18,194 - ERROR: error occurred while scraping https://spa16.scrape.center/1422\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\59427\\AppData\\Local\\Temp\\ipykernel_12228\\3986696478.py\", line 7, in scrape_api\n",
      "    async with session.get(url) as response:\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 1141, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py\", line 560, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py\", line 899, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\site-packages\\aiohttp\\streams.py\", line 616, in read\n",
      "    await self._waiter\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\tasks.py\", line 339, in __wakeup\n",
      "    future.result()\n",
      "  File \"d:\\anaconda3\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "aiohttp.client_exceptions.ClientOSError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(results, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 9\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\u001b[38;5;241m.\u001b[39mrun_until_complete(main())\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\nest_asyncio.py:90\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\asyncio\\futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\asyncio\\tasks.py:269\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    267\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 269\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m session \u001b[38;5;241m=\u001b[39m aiohttp\u001b[38;5;241m.\u001b[39mClientSession()\n\u001b[0;32m      5\u001b[0m scrape_index_tasks \u001b[38;5;241m=\u001b[39m [asyncio\u001b[38;5;241m.\u001b[39mensure_future(scrape_index(page)) \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, PAGE_NUMBER \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mscrape_index_tasks)\n\u001b[0;32m      7\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(results, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\asyncio\\tasks.py:339\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 339\u001b[0m         future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    341\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\asyncio\\tasks.py:269\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    267\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 269\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_cancel:\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m, in \u001b[0;36mscrape_index\u001b[1;34m(page)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape_index\u001b[39m(page):\n\u001b[0;32m      2\u001b[0m     url \u001b[38;5;241m=\u001b[39m INDEX_URL\u001b[38;5;241m.\u001b[39mformat(offset\u001b[38;5;241m=\u001b[39mPAGE_SIZE \u001b[38;5;241m*\u001b[39m (page \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m scrape_api(url)\n",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m, in \u001b[0;36mscrape_api\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscraping \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, url)\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39mget(url) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m aiohttp\u001b[38;5;241m.\u001b[39mClientError:\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py:1141\u001b[0m, in \u001b[0;36m_BaseRequestContextManager.__aenter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _RetType:\n\u001b[1;32m-> 1141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coro\n\u001b[0;32m   1142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\aiohttp\\client.py:560\u001b[0m, in \u001b[0;36mClientSession._request\u001b[1;34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, proxy_headers, trace_request_ctx, read_bufsize)\u001b[0m\n\u001b[0;32m    558\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m req\u001b[38;5;241m.\u001b[39msend(conn)\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstart(conn)\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m    562\u001b[0m     resp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\aiohttp\\client_reqrep.py:894\u001b[0m, in \u001b[0;36mClientResponse.start\u001b[1;34m(self, connection)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mprotocol\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;241m=\u001b[39m connection\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timer:\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    896\u001b[0m         \u001b[38;5;66;03m# read response\u001b[39;00m\n\u001b[0;32m    897\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\aiohttp\\helpers.py:720\u001b[0m, in \u001b[0;36mTimerContext.__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cancelled:\n\u001b[1;32m--> 720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "async def main():\n",
    "    global session\n",
    "    session = aiohttp.ClientSession()\n",
    "    scrape_index_tasks = [asyncio.ensure_future(scrape_index(page)) for page in range(1, PAGE_NUMBER + 1)]\n",
    "    results = await asyncio.gather(*scrape_index_tasks)\n",
    "    logging.info('results %s', json.dumps(results, ensure_ascii=False, indent=2))\n",
    "if __name__== '__main__':\n",
    "    asyncio.get_event_loop().run_until_complete(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for index_data in results:\n",
    "    if not index_data: continue\n",
    "for item in index_data.get('results'):\n",
    "        ids.append(item.get('id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from motor.motor_asyncio import AsyncIOMotorClient\n",
    "MONGO_CONNECTION_STRING = 'mongodb://localhost:27017'\n",
    "MONGO_DB_NAME = 'books'\n",
    "MONGO_COLLECTION_NAME = 'books'\n",
    "client = AsyncIOMotorClient(MONGO_CONNECTION_STRING)\n",
    "db = client[MONGO_DB_NAME]\n",
    "collection = db[MONGO_COLLECTION_NAME]\n",
    "async def save_data(data):\n",
    "    logging.info('saving data %s', data)\n",
    "    if data:\n",
    "        return await collection.update_one({'id':data.get('id')},{'$set':data},upsert=True)\n",
    "\n",
    "async def scrape_detail(id):\n",
    "    url = DETAIL_URL.format(id=id)\n",
    "    data = await scrape_api(url)\n",
    "    await save_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scrape_detail_tasks \u001b[38;5;241m=\u001b[39m [asyncio\u001b[38;5;241m.\u001b[39mensure_future(scrape_detail(\u001b[38;5;28mid\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ids]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait(scrape_detail_tasks)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m session\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ids' is not defined"
     ]
    }
   ],
   "source": [
    "scrape_detail_tasks = [asyncio.ensure_future(scrape_detail(id)) for id in ids]\n",
    "await asyncio.wait(scrape_detail_tasks)\n",
    "await session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
